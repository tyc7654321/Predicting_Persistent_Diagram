{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Dataloader import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PerUnet import *\n",
    "from MultiCNN import *\n",
    "from MinMaxNet import *\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import scgen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "lr = 0.1\n",
    "batch_size = 32\n",
    "model_name = 2\n",
    "weights_number = 1\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=None)\n",
    "new_trainset = CIFAR10dataset(trainset)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(new_trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=None)\n",
    "new_testset = CIFAR10dataset(testset)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(new_testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class WMSELoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, inputs, output):\n",
    "        return torch.sum(self.weights * (inputs - output) ** 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if (type(m) == nn.Conv2d) or (type(m) == nn.ConvTranspose2d) or (type(m) == nn.Linear) or (type(m) == nn.Conv3d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "\n",
    "if model_name == 0:\n",
    "    model = PerUnet()\n",
    "    MODEL_TYPE = str('PerUnet')\n",
    "elif model_name == 1:\n",
    "    model = MultiCNN()\n",
    "    MODEL_TYPE = str('MultiCNN')\n",
    "elif model_name == 2:\n",
    "    model = MinMaxNet()\n",
    "    MODEL_TYPE = str('MinMaxNet')\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "weights1 = (torch.arange(20, 0, -1)).float() /210\n",
    "\n",
    "if weights_number == 0:\n",
    "    criterion = nn.MSELoss()\n",
    "elif weights_number == 1:\n",
    "    criterion = WMSELoss(weights = weights1)\n",
    "\n",
    "#print(weights)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.1)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32])\n",
      "torch.Size([32, 20])\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "tensor(5.6148, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, lifetime, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "#plt.imshow(torchvision.utils.make_grid(images))\n",
    "print(images.shape)\n",
    "print(lifetime.shape)\n",
    "#print(pdgm)\n",
    "\n",
    "inputs_image = torch.as_tensor(images, device=torch.device('cpu'))\n",
    "GT_image = torch.as_tensor(lifetime, dtype=torch.float32, device=torch.device('cpu'))\n",
    "outputs = model(inputs_image)\n",
    "\n",
    "print(outputs.type())\n",
    "print(GT_image.type())\n",
    "loss = criterion(outputs, GT_image)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def progressBar(i, max, text):\n",
    "    bar_size = 30\n",
    "    j = i / max\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(\n",
    "        f\"[{'=' * int(bar_size * j):{bar_size}s}] {int(100 * j)}%  {text}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def train():\n",
    "\n",
    "    train_loss_list = list()\n",
    "    val_loss_list = list()\n",
    "    test_loss_list = list()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch:\", epoch)\n",
    "        ts = time.time()\n",
    "\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        for iter, (X, Y, labels) in enumerate(trainloader):\n",
    "\n",
    "            # training on the first 10000 images\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs_image = torch.as_tensor(X, device=torch.device('cpu'))\n",
    "            GT_image = torch.as_tensor(Y, dtype=torch.float32, device=torch.device('cpu'))\n",
    "\n",
    "            #start = torch.cuda.Event(enable_timing=True)\n",
    "            #end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "\n",
    "            outputs = model(inputs_image)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, GT_image)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            #start.record()\n",
    "            optimizer.step()\n",
    "            #end.record()\n",
    "\n",
    "            # Waits for everything to finish running\n",
    "            #torch.cuda.synchronize()\n",
    "\n",
    "            #print(start.elapsed_time(end))\n",
    "\n",
    "            train_loss += loss.item() / len(trainloader) / batch_size\n",
    "\n",
    "            progressBar(iter + 1, len(trainloader),\n",
    "                            \"Train Progress\")\n",
    "\n",
    "            '''\n",
    "\n",
    "            # validating on the rest 10000 images\n",
    "            while iter > 0.2 * len(trainloader) and iter <= 0.4 * len(trainloader):\n",
    "                inputs_image = torch.as_tensor(X, device=torch.device('cuda'))\n",
    "                GT_image = torch.as_tensor(Y, dtype=torch.float32, device=torch.device('cuda'))\n",
    "\n",
    "                outputs = model(inputs_image)\n",
    "                loss = criterion(outputs, GT_image)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                progressBar(iter + 1, 0.2 * len(trainloader) / batch_size,\n",
    "                        \"Validation Progress\")\n",
    "\n",
    "            if iter > 0.4 * len(new_trainset):\n",
    "                break\n",
    "            '''\n",
    "        print(\"\\n train loss {}\".format(train_loss))\n",
    "        train_loss_list.append(train_loss)\n",
    "        #val_loss_list.append(val_loss)\n",
    "\n",
    "        # testing on 10000 images\n",
    "        for iter, (X, Y, labels) in enumerate(testloader):\n",
    "\n",
    "            inputs_image = torch.as_tensor(X, device=torch.device('cpu'))\n",
    "            GT_image = torch.as_tensor(Y, dtype=torch.float32, device=torch.device('cpu'))\n",
    "\n",
    "            outputs = model(inputs_image)\n",
    "            loss = criterion(outputs, GT_image)\n",
    "\n",
    "            test_loss += loss.item() / len(testloader)\n",
    "\n",
    "            progressBar(iter + 1, len(testloader),\n",
    "                        \"Test Progress\")\n",
    "\n",
    "        print(\"\\n test loss {}\".format(test_loss))\n",
    "\n",
    "        test_loss_list.append(test_loss)\n",
    "\n",
    "        plot_performance(train_loss_list, test_loss_list)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(model, 'Model'+ MODEL_TYPE + \"_lr=\" +str(lr) + 'weight=' + str(weights_number))\n",
    "    return\n",
    "\n",
    "def plot_performance(train_loss_list, test_loss_list):\n",
    "    Title = \"Model=\" + MODEL_TYPE + \\\n",
    "            \";  batch_size=\" + str(batch_size) + \\\n",
    "            \";  lr=\" + str(lr) + \\\n",
    "            \";  epochs=\" + str(epochs) + \\\n",
    "            \";  Weighted Loss = weights\" + str(weights_number)\n",
    "    plt.plot(train_loss_list, label=\"Train Loss\")\n",
    "    #plt.plot(val_loss_list, label=\"Validation Loss\")\n",
    "    plt.plot(test_loss_list, label=\"Test Loss\")\n",
    "    plt.legend(bbox_to_anchor=(0.8, 1), loc='upper left')\n",
    "    #plt.set(xlabel='epoch', ylabel='loss')\n",
    "    plt.title(Title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1470 1517 1947 ...  802 2108 1810]\n",
      "[ 456  846 1694 ...  679  382 1445]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.choice(range(0,2437), 1949)\n",
    "y = np.random.choice(range(0,2437), 1222)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor(2),\n",
      "indices=tensor(1))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1,2,2])\n",
    "\n",
    "print(torch.max(a, dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}